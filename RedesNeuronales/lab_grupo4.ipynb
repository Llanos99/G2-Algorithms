{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41TXUwo9qaCK"
      },
      "source": [
        "###Codigo e implementación https://github.com/Psychofun/Red-Neuronal-Numpy\n",
        "Autor: PsyFun\n",
        "##Preprocesamiento de los datos, para estandarizar (\"gre\",\"gpa\") e individualizar la caracteristica categorica \"rank\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUZEHEtB-wNB",
        "outputId": "5cce6034-e05b-4324-a359-9191da12df96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJZTjn-Jk-NB",
        "outputId": "da5c282e-97f1-4e1b-cf30-0c6088be32c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            admit         gre         gpa       rank\n",
            "count  400.000000  400.000000  400.000000  400.00000\n",
            "mean     0.317500  587.700000    3.389900    2.48500\n",
            "std      0.466087  115.516536    0.380567    0.94446\n",
            "min      0.000000  220.000000    2.260000    1.00000\n",
            "25%      0.000000  520.000000    3.130000    2.00000\n",
            "50%      0.000000  580.000000    3.395000    2.00000\n",
            "75%      1.000000  660.000000    3.670000    3.00000\n",
            "max      1.000000  800.000000    4.000000    4.00000\n",
            "(400, 4)\n",
            "   admit  gre   gpa  rank\n",
            "0      0  380  3.61     3\n",
            "1      1  660  3.67     3\n",
            "2      1  800  4.00     1\n",
            "3      1  640  3.19     4\n",
            "4      0  520  2.93     4\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "admissions = pd.read_csv('/content/drive/MyDrive/7ma_matricula/Algoritmos/binary.csv')\n",
        "print(admissions.describe())\n",
        "print(admissions.shape)\n",
        "print(admissions.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9XG_Iz8sAaa"
      },
      "source": [
        "#Conversion de una variable categorica \"rank\" a variables binarias \"rank_1\",\"rank_2\",\"rank_3\", \"rank_4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcgNCowrsIVz",
        "outputId": "fb5889d6-3ab5-4a2d-f81b-15daa8cfee1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            admit         gre         gpa       rank      rank_1      rank_2  \\\n",
            "count  400.000000  400.000000  400.000000  400.00000  400.000000  400.000000   \n",
            "mean     0.317500  587.700000    3.389900    2.48500    0.152500    0.377500   \n",
            "std      0.466087  115.516536    0.380567    0.94446    0.359955    0.485369   \n",
            "min      0.000000  220.000000    2.260000    1.00000    0.000000    0.000000   \n",
            "25%      0.000000  520.000000    3.130000    2.00000    0.000000    0.000000   \n",
            "50%      0.000000  580.000000    3.395000    2.00000    0.000000    0.000000   \n",
            "75%      1.000000  660.000000    3.670000    3.00000    0.000000    1.000000   \n",
            "max      1.000000  800.000000    4.000000    4.00000    1.000000    1.000000   \n",
            "\n",
            "           rank_3      rank_4  \n",
            "count  400.000000  400.000000  \n",
            "mean     0.302500    0.167500  \n",
            "std      0.459916    0.373889  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000    0.000000  \n",
            "50%      0.000000    0.000000  \n",
            "75%      1.000000    0.000000  \n",
            "max      1.000000    1.000000  \n",
            "(400, 7)\n",
            "   admit  gre   gpa  rank_1  rank_2  rank_3  rank_4\n",
            "0      0  380  3.61       0       0       1       0\n",
            "1      1  660  3.67       0       0       1       0\n",
            "2      1  800  4.00       1       0       0       0\n",
            "3      1  640  3.19       0       0       0       1\n",
            "4      0  520  2.93       0       0       0       1\n"
          ]
        }
      ],
      "source": [
        "data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)\n",
        "print(data.describe())\n",
        "data = data.drop('rank', axis=1)\n",
        "print(data.shape)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmEtWaKru5at"
      },
      "source": [
        "Estandarizacion de las variables (\"gre\",\"gpa\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5SSkXX3u5nl",
        "outputId": "eac496ec-2460-40b4-9dd0-93f2c67f6fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 7)\n",
            "            admit           gre           gpa      rank_1      rank_2  \\\n",
            "count  400.000000  4.000000e+02  4.000000e+02  400.000000  400.000000   \n",
            "mean     0.317500 -3.907985e-16  2.198242e-16    0.152500    0.377500   \n",
            "std      0.466087  1.000000e+00  1.000000e+00    0.359955    0.485369   \n",
            "min      0.000000 -3.183094e+00 -2.968993e+00    0.000000    0.000000   \n",
            "25%      0.000000 -5.860633e-01 -6.829288e-01    0.000000    0.000000   \n",
            "50%      0.000000 -6.665712e-02  1.340106e-02    0.000000    0.000000   \n",
            "75%      1.000000  6.258844e-01  7.360075e-01    0.000000    1.000000   \n",
            "max      1.000000  1.837832e+00  1.603135e+00    1.000000    1.000000   \n",
            "\n",
            "           rank_3      rank_4  \n",
            "count  400.000000  400.000000  \n",
            "mean     0.302500    0.167500  \n",
            "std      0.459916    0.373889  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000    0.000000  \n",
            "50%      0.000000    0.000000  \n",
            "75%      1.000000    0.000000  \n",
            "max      1.000000    1.000000  \n",
            "   admit       gre       gpa  rank_1  rank_2  rank_3  rank_4\n",
            "0      0 -1.798011  0.578348       0       0       1       0\n",
            "1      1  0.625884  0.736008       0       0       1       0\n",
            "2      1  1.837832  1.603135       1       0       0       0\n",
            "3      1  0.452749 -0.525269       0       0       0       1\n",
            "4      0 -0.586063 -1.208461       0       0       0       1\n"
          ]
        }
      ],
      "source": [
        "# Standarize features\n",
        "for field in ['gre', 'gpa']:\n",
        "    mean, std = data[field].mean(), data[field].std()\n",
        "    data.loc[:,field] = (data[field]-mean)/std\n",
        "print(data.shape)\n",
        "print(data.describe())\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVB1VUJJ3bSb"
      },
      "source": [
        "dividir el conjunto de datos para entrenamiento y evaluación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPSE6sC84O8F",
        "outputId": "59c2f192-4c5e-46d4-c245-9b68046517af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RangeIndex(start=0, stop=400, step=1)\n"
          ]
        }
      ],
      "source": [
        "print(data.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SylZqIL930bt",
        "outputId": "f83f626a-3368-44a7-d97b-4066c9bdbbc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(360, 7)\n",
            "(40, 7)\n"
          ]
        }
      ],
      "source": [
        "# Split off random 10% of the data for testing\n",
        "np.random.seed(21)\n",
        "\n",
        "sample = np.random.choice(data.index, size=int(len(data)*0.9), replace=False)\n",
        "train_data, test_data = data.iloc[sample], data.drop(sample)\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1pEVm7X473r"
      },
      "source": [
        "División de los datos en caracteristicas y etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdlScpB946Py"
      },
      "outputs": [],
      "source": [
        "features, targets = train_data.drop('admit', axis=1), train_data['admit']\n",
        "features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GDBHBbT5WtC"
      },
      "source": [
        "Función de Activación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X5cn6oa5amd"
      },
      "outputs": [],
      "source": [
        "def sigmoide(x):\n",
        "    return 1/(1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5PDFAdG5TIm",
        "outputId": "9227617c-3d6a-499e-c76f-0249b4a4e107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 2)\n",
            "(2,)\n",
            "Costo de entrenamiento:  0.2377095517475239\n",
            "Costo de entrenamiento:  0.2372764787497153\n",
            "Costo de entrenamiento:  0.23685185035695452\n",
            "Costo de entrenamiento:  0.23643549079189158\n",
            "Costo de entrenamiento:  0.23602722752904412\n",
            "Costo de entrenamiento:  0.23562689126819572\n",
            "Costo de entrenamiento:  0.23523431590566762\n",
            "Costo de entrenamiento:  0.23484933850364967\n",
            "Costo de entrenamiento:  0.23447179925776251\n",
            "Costo de entrenamiento:  0.23410154146301557\n",
            "Precisión: 0.650\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "n_hidden = 2 # Número de unidades en la capa escondida\n",
        "epochs = 300 # Número de iteraciones sobre el conjunto de entrenamiento\n",
        "alpha = 0.01 # Taza de aprendizaje\n",
        "np.random.seed(1)\n",
        "\n",
        "ult_costo = None \n",
        "\n",
        "m,k = features.shape # Número de ejemplos de entrenamiento, número de dimensiones en los datos \n",
        "# Inicialización de los pesos\n",
        "entrada_escondida = np.random.normal(scale = 1/k**0.5,size = (k,n_hidden))\n",
        "escondida_salida = np.random.normal(scale = 1/k**0.5,size = n_hidden)\n",
        "print(entrada_escondida.shape)\n",
        "print(escondida_salida.shape)\n",
        "# Entrenamiento\n",
        "for e in range(epochs):\n",
        "    # Variables para el gradiente\n",
        "    gradiente_entrada_escondida = np.zeros(entrada_escondida.shape)\n",
        "    gradiente_escondida_salida =  np.zeros(escondida_salida.shape)\n",
        "    # Itera sobre el conjunto de entrenamiento\n",
        "    for x,y in zip(features.values,targets):\n",
        "        # Pasada hacia adelande (forward pass) or forward propagation\n",
        "        z = sigmoide(np.matmul(x, entrada_escondida))\n",
        "        y_ =sigmoide(np.matmul(escondida_salida,z)) # predicción \n",
        "        # Pasada hacia atrás (backward pass)\n",
        "        salida_error = (y - y_) * y_ *(1- y_)\n",
        "        escondida_error = np.dot(salida_error, escondida_salida) * z * (1 -z)\n",
        "\n",
        "        gradiente_entrada_escondida += escondida_error * x[:,None]\n",
        "        gradiente_escondida_salida += salida_error * z \n",
        "    # Actualiza los parámetros (pesos)\n",
        "    entrada_escondida += alpha * gradiente_entrada_escondida / m \n",
        "    escondida_salida +=  alpha * gradiente_escondida_salida / m \n",
        "\n",
        "    if e % (epochs / 10 ) == 0:\n",
        "        z = sigmoide(np.dot(features.values, entrada_escondida))\n",
        "        y_ = sigmoide(np.dot(z, escondida_salida))\n",
        "\n",
        "        # Función de costo\n",
        "        costo = np.mean(( y_ - targets)**2 )\n",
        "\n",
        "        if ult_costo  and ult_costo < costo:\n",
        "            print(\"Costo de  entrenamiento: \", costo, \" ADVERTENCIA -  Costo subiendo\")\n",
        "        else:\n",
        "            print(\"Costo de entrenamiento: \", costo )\n",
        "        \n",
        "        ult_costo = costo \n",
        "\n",
        "#  Precisión en los datos de prueba \n",
        "z = sigmoide(np.dot(features_test, entrada_escondida))\n",
        "y_ = sigmoide(np.dot(z, escondida_salida))\n",
        "\n",
        "predicciones =  y_ > 0.5 \n",
        "precision = np.mean(predicciones == targets_test)\n",
        "print(\"Precisión: {:.3f}\".format(precision))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cantidad de Épocas \n",
        "\n",
        "En este experimento buscamos encontrar una cantidad de épocas suficientes para entrenar nuestra red neuronal, sin entrar en un \"over-fitting\" \n"
      ],
      "metadata": {
        "id": "lcWRRgdjUa6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "n_hidden = 2 # Número de unidades en la capa escondida\n",
        "epochs = 0 # Número de iteraciones sobre el conjunto de entrenamiento\n",
        "alpha = 0.01 # Taza de aprendizaje\n",
        "\n",
        "tol = 0.65  # La tolerancia de aprendizaje que definimos para nuestro modelo\n",
        "precision = 0 # Precision con la que la red neuronal hace predicciónes\n",
        "\n",
        "ult_costo = None \n",
        "\n",
        "m,k = features.shape # Número de ejemplos de entrenamiento, número de dimensiones en los datos \n",
        "# Inicialización de los pesos\n",
        "entrada_escondida = np.random.normal(scale = 1/k**0.5,size = (k,n_hidden))\n",
        "print(entrada_escondida)\n",
        "escondida_salida = np.random.normal(scale = 1/k**0.5,size = n_hidden)\n",
        "print(escondida_salida)\n",
        "print(entrada_escondida.shape)\n",
        "print(escondida_salida.shape)\n",
        "# Entrenamiento\n",
        "while precision < tol:\n",
        "    epochs += 1\n",
        "    # Variables para el gradiente\n",
        "    gradiente_entrada_escondida = np.zeros(entrada_escondida.shape)\n",
        "    gradiente_escondida_salida =  np.zeros(escondida_salida.shape)\n",
        "    # Itera sobre el conjunto de entrenamiento\n",
        "    for x,y in zip(features.values,targets):\n",
        "        # Pasada hacia adelande (forward pass) or forward propagation\n",
        "        z = sigmoide(np.matmul(x, entrada_escondida))\n",
        "        y_ =sigmoide(np.matmul(escondida_salida,z)) # predicción \n",
        "        # Pasada hacia atrás (backward pass)\n",
        "        salida_error = (y - y_) * y_ *(1- y_)\n",
        "        escondida_error = np.dot(salida_error, escondida_salida) * z * (1 -z)\n",
        "\n",
        "        gradiente_entrada_escondida += escondida_error * x[:,None]\n",
        "        gradiente_escondida_salida += salida_error * z \n",
        "    # Actualiza los parámetros (pesos)\n",
        "    entrada_escondida += alpha * gradiente_entrada_escondida / m \n",
        "    escondida_salida +=  alpha * gradiente_escondida_salida / m \n",
        "\n",
        "    #  Precisión en los datos de prueba \n",
        "    z = sigmoide(np.dot(features, entrada_escondida))\n",
        "    y_ = sigmoide(np.dot(z, escondida_salida))\n",
        "\n",
        "    predicciones =  y_ > 0.5 \n",
        "    precision = np.mean(predicciones == targets)\n",
        "\n",
        "    if epochs % (100) == 0:\n",
        "        z = sigmoide(np.dot(features.values, entrada_escondida))\n",
        "        y_ = sigmoide(np.dot(z, escondida_salida))\n",
        "\n",
        "        # Función de costo\n",
        "        costo = np.mean(( y_ - targets)**2 )\n",
        "\n",
        "        if ult_costo  and ult_costo < costo:\n",
        "            print(\"Costo de  entrenamiento: \", costo, \" ADVERTENCIA -  Costo subiendo\")\n",
        "        else:\n",
        "            print(\"Costo de entrenamiento: \", costo )\n",
        "            print(\"Precisión: {:.3f}\".format(precision))\n",
        "            print(\"Numero de épocas: \", epochs)\n",
        "        \n",
        "        ult_costo = costo \n",
        "\n",
        "print(\"Modelo entrenado exitosamente !\")\n",
        "print(\"Precisión: {:.3f}\".format(precision))\n",
        "print(\"Numero de épocas: \", epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoDJZhbqUZhW",
        "outputId": "f672bab9-004b-4518-aa75-fd9144e8d152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.12306309  0.31317405]\n",
            " [-0.08645405 -0.02350285]\n",
            " [-0.76840206 -0.23939043]\n",
            " [ 0.33997091 -0.60476078]\n",
            " [ 0.17315152 -0.05567747]\n",
            " [-0.40734721 -0.05260147]]\n",
            "[ 0.69885416 -0.59842473]\n",
            "(6, 2)\n",
            "(2,)\n",
            "Costo de entrenamiento:  0.2604904269197874\n",
            "Precisión: 0.378\n",
            "Numero de épocas:  100\n",
            "Costo de entrenamiento:  0.2580302037596837\n",
            "Precisión: 0.397\n",
            "Numero de épocas:  200\n",
            "Costo de entrenamiento:  0.25569749959291455\n",
            "Precisión: 0.442\n",
            "Numero de épocas:  300\n",
            "Costo de entrenamiento:  0.25348605729127915\n",
            "Precisión: 0.467\n",
            "Numero de épocas:  400\n",
            "Costo de entrenamiento:  0.25138975866786617\n",
            "Precisión: 0.486\n",
            "Numero de épocas:  500\n",
            "Costo de entrenamiento:  0.24940265262769856\n",
            "Precisión: 0.536\n",
            "Numero de épocas:  600\n",
            "Costo de entrenamiento:  0.24751897711508844\n",
            "Precisión: 0.542\n",
            "Numero de épocas:  700\n",
            "Costo de entrenamiento:  0.2457331756147034\n",
            "Precisión: 0.556\n",
            "Numero de épocas:  800\n",
            "Costo de entrenamiento:  0.2440399089228966\n",
            "Precisión: 0.597\n",
            "Numero de épocas:  900\n",
            "Costo de entrenamiento:  0.24243406285560248\n",
            "Precisión: 0.633\n",
            "Numero de épocas:  1000\n",
            "Costo de entrenamiento:  0.2409107525032205\n",
            "Precisión: 0.647\n",
            "Numero de épocas:  1100\n",
            "Modelo entrenado exitosamente !\n",
            "Precisión: 0.650\n",
            "Numero de épocas:  1184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cambio de función de activación\n",
        "\n",
        "En este punto, se remplaza la función sigmoide por la tangente hiperbólica, para observar el comportamiento de la red neuronal"
      ],
      "metadata": {
        "id": "USIqfoI_bosg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "n_hidden = 2 # Número de unidades en la capa escondida\n",
        "epochs = 300 # Número de iteraciones sobre el conjunto de entrenamiento\n",
        "alpha = 0.01 # Taza de aprendizaje\n",
        "np.random.seed(1)\n",
        "ult_costo = None \n",
        "\n",
        "m,k = features.shape # Número de ejemplos de entrenamiento, número de dimensiones en los datos \n",
        "# Inicialización de los pesos\n",
        "entrada_escondida = np.random.normal(scale = 1/k**0.5,size = (k,n_hidden))\n",
        "escondida_salida = np.random.normal(scale = 1/k**0.5,size = n_hidden)\n",
        "print(entrada_escondida.shape)\n",
        "print(escondida_salida.shape)\n",
        "# Entrenamiento\n",
        "for e in range(epochs):\n",
        "    # Variables para el gradiente\n",
        "    gradiente_entrada_escondida = np.zeros(entrada_escondida.shape)\n",
        "    gradiente_escondida_salida =  np.zeros(escondida_salida.shape)\n",
        "    # Itera sobre el conjunto de entrenamiento\n",
        "    for x,y in zip(features.values,targets):\n",
        "        # Pasada hacia adelande (forward pass) or forward propagation\n",
        "        z = np.tanh(np.matmul(x, entrada_escondida))\n",
        "        y_ =np.tanh(np.matmul(escondida_salida,z)) # predicción \n",
        "        # Pasada hacia atrás (backward pass)\n",
        "        salida_error = (y - y_) * (1 - np.power(y_,2))\n",
        "        escondida_error = np.dot(salida_error, escondida_salida) * (1 - np.power(z,2))\n",
        "\n",
        "        gradiente_entrada_escondida += escondida_error * x[:,None]\n",
        "        gradiente_escondida_salida += salida_error * z \n",
        "    # Actualiza los parámetros (pesos)\n",
        "    entrada_escondida += alpha * gradiente_entrada_escondida / m \n",
        "    escondida_salida +=  alpha * gradiente_escondida_salida / m \n",
        "\n",
        "    if e % (epochs / 10 ) == 0:\n",
        "        z = np.tanh(np.dot(features.values, entrada_escondida))\n",
        "        y_ = np.tanh(np.dot(z, escondida_salida))\n",
        "\n",
        "        # Función de costo\n",
        "        costo = np.mean(( y_ - targets)**2 )\n",
        "\n",
        "        if ult_costo  and ult_costo < costo:\n",
        "            print(\"Costo de  entrenamiento: \", costo, \" ADVERTENCIA -  Costo subiendo\")\n",
        "        else:\n",
        "            print(\"Costo de entrenamiento: \", costo )\n",
        "        \n",
        "        ult_costo = costo \n",
        "\n",
        "#  Precisión en los datos de prueba \n",
        "z = sigmoide(np.dot(features_test, entrada_escondida))\n",
        "y_ = sigmoide(np.dot(z, escondida_salida))\n",
        "\n",
        "predicciones =  y_ > 0.5 \n",
        "precision = np.mean(predicciones == targets_test)\n",
        "print(\"Precisión: {:.3f}\".format(precision))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrU7d-b2bn8x",
        "outputId": "5163d448-96eb-4525-e41e-a5212d84f351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 2)\n",
            "(2,)\n",
            "Costo de entrenamiento:  0.30965898521493956\n",
            "Costo de entrenamiento:  0.2907808591951554\n",
            "Costo de entrenamiento:  0.2769403554139474\n",
            "Costo de entrenamiento:  0.26673328485052494\n",
            "Costo de entrenamiento:  0.25912164031912954\n",
            "Costo de entrenamiento:  0.2533579499725873\n",
            "Costo de entrenamiento:  0.2489110846115626\n",
            "Costo de entrenamiento:  0.24540572765162427\n",
            "Costo de entrenamiento:  0.24257689979508013\n",
            "Costo de entrenamiento:  0.24023718194086569\n",
            "Precisión: 0.725\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}